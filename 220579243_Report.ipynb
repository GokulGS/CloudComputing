{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bkdboLFBuj6I"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMFDj5Tdg08LVzjTKHSnNFL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GokulGS/CloudComputing/blob/main/220579243_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Performance evaluation of Terapixel rendering in Cloud (Super)computing**"
      ],
      "metadata": {
        "id": "bkdboLFBuj6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**\n",
        "The Objective in this report is to investigate aspect of the Performace evaluation of Terapixel rendering in cloud computing. The issue we aimed to address in this study was how to provide the supercomputer scale resources required to build a realistic terapixel picture of Newcastle upon Tyne and its environmental data as recorded by the Newcastle Urban Observatory. The three key objectives of this work are to: create a supercomputer architecture for scalable visualization using the public cloud; produce a terapixel 3D city visualization supporting daily updates; undertake a rigorous evaluation of cloud supercomputing for compute intensive visualization applications.  "
      ],
      "metadata": {
        "id": "3MOjrd2fhxGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Methodology**\n",
        "The EDA process is the sole subject of this study, which is described in terms of a hierarchical process model. This model is made up of sets of tasks that are detailed at various levels. In order to design a data mining project, this provides a systematic strategy.\n",
        "\n",
        "## Business Understanding\n",
        "Identifying the requirements and objectives of the project from a commercial perspective is the main purpose of this initial stage. It is therefore possible to identify the data mining challenge and develop a basic plan of attack to reach the objectives using this understanding.\n",
        "\n",
        "\n",
        "\n",
        "## Data Understanding\n",
        "The preparation of the data is an essential part in exploratory data analysis. It describes the procedure for locating and importing data into our system. Good, trustworthy data may be purchased from private groups or acquired on a variety of public websites. The dataset below was produced using inputs from system metrics and application checkpoints during the creation of a terapixel picture. The TeraScope dataset may be used to solve a number of different issues. For this analysis, there are 3 data file has been used and for easy connection the files are stored in the google drive and connected and called using the below set of code.\n",
        "\n",
        "```\n",
        "data1=pd.read_csv('/content/gdrive/MyDrive/Cloud_computing/application-checkpoints.csv')\n",
        "data2=pd.read_csv('/content/gdrive/MyDrive/Cloud_computing/task-x-y.csv')\n",
        "data3=pd.read_csv('/content/gdrive/MyDrive/Cloud_computing/gpu.csv')\n",
        "```\n",
        "\n",
        "1.   ***application-checkpoints.csv***\n",
        "\n",
        "|Field Name |  Data Type |Description|Example|\n",
        "|-------|:-----|:-----|:-----|\n",
        "|timestamp |DataTime|Start time and End time of each event type | \"2018-11-08T07:41:55.921Z\"|\n",
        "|hostname|String|Hostname of the virtual machine|\"0d56a730076643d585f77e00d2d8521a00000N\"|\n",
        "|eventName|String|Events occuring within the rendering application|\"Tiling\" \"Saving Config\" \"Render\" \"TotalRender\" \"Uploading\"|\n",
        "|eventType|String|Type of events|\"START\" \"STOP\"|\n",
        "|jobId |String|Azure batch job ID |\"1024-lvl12-7e026be3-5fd0-48ee-b7d1-abd61f747705\"\n",
        "|taskId|String|ID of the Azure batch task| \"b47f0263-ba1c-48a7-8d29-4bf021b72043\"|\n",
        "|\n",
        "|\n",
        "\n",
        "2.   ***gpu.csv***\n",
        "\n",
        "|Field Name |  Data Type |Description|Example|\n",
        "|-------|:-----|:-----|:-----|\n",
        "|timestamp |DataTime|Start time and End time of each event type | \"2018-11-08T07:41:55.921Z\"|\n",
        "|hostname|String|Hostname of the virtual machine|\"0d56a730076643d585f77e00d2d8521a00000N\"|\n",
        "|gpuSerial|int|The serial number of the physical GPU card|\"0323217055910\"|\n",
        "|gpuUUID|String|The unique system id of the GPU unit|\"GPU-1d1602dc-f615-a7c7-ab53-fb4a7a479534\"|\n",
        "|powerDrawWatt |float|Power draw of the GPU in watts |\"121.35\"\n",
        "|gpuTempC|float|GPU temperature in Celsius| \"53\"|\n",
        "|gpuUtilPerc|float|Percent utilisation of the GPU Core(s)| \"85\"|\n",
        "|gpuMemUtilPerc|float|Percent utilisation of the GPU memory| \"65\"|\n",
        "|\n",
        "|\n",
        "\n",
        "3.   ***task-x-y.csv***\n",
        "\n",
        "|Field Name |  Data Type |Description|Example|\n",
        "|-------|:-----|:-----|:-----|\n",
        "|jobId |String|Azure batch job ID |\"1024-lvl12-7e026be3-5fd0-48ee-b7d1-abd61f747705\"\n",
        "|taskId|String|ID of the Azure batch task| \"b47f0263-ba1c-48a7-8d29-4bf021b72043\"|\n",
        "|x |int|X co-ordinate of the image tile being rendered |\"10\"\n",
        "|y|int|Y co-ordinate of the image tile being rendered| \"125\"|\n",
        "|level|int|The visualisation created is a zoomable \"google maps style\"| \"8\"|\n",
        "|\n",
        "\n",
        "## Data preparation\n",
        "The process of eliminating redundant variables and values from your dataset and getting rid of any errors is known as data preparation or cleaning. Such abnormalities might significantly distort the data, which will have a negative impact on the outcomes. \n",
        "\n",
        "The duplicate records has been removed from the data files. Below code will get the duplicate records and non duplicate records. Then duplicate recodrs has been appended to the non duplicate records. \n",
        "\n",
        "```\n",
        "from pandas.io.parsers.readers import csv\n",
        "from os import write\n",
        "\n",
        "q1=\"\"\"select timestamp,hostname,eventName,eventType,jobId,taskId,count(*) from data1 group by 1,2,3,4,5,6 having count(*)>1;\"\"\"\n",
        "dup_rec=pysqldf(q1)\n",
        "\n",
        "q2=\"\"\"select timestamp,hostname,eventName,eventType,jobId,taskId,count(*) from data1 group by 1,2,3,4,5,6 having count(*)=1;\"\"\"\n",
        "non_dup_rec=pysqldf(q2)\n",
        "\n",
        "cdata1=non_dup_rec.iloc[:,:6].append(dup_rec.iloc[:,:6])\n",
        "\n",
        "\n",
        "q1_3=\"\"\"select timestamp,hostname,gpuSerial,gpuUUID,powerDrawWatt,gpuTempC,gpuUtilPerc,gpuMemUtilPerc,count(*) from data3 group by 1,2,3,4,5,6,7,8 having count(*)>1;\"\"\"\n",
        "dup_rec3=pysqldf(q1_3)\n",
        "\n",
        "q1_4=\"\"\"select timestamp,hostname,gpuSerial,gpuUUID,powerDrawWatt,gpuTempC,gpuUtilPerc,gpuMemUtilPerc,count(*) from data3 group by 1,2,3,4,5,6,7,8 having count(*)=1;\"\"\"\n",
        "non_dup_rec3=pysqldf(q1_4)\n",
        "\n",
        "cdata3=non_dup_rec3.iloc[:,:8].append(dup_rec3.iloc[:,:8])\n",
        "\n",
        "```\n",
        "\n",
        "## Modeling\n",
        "This process contains the modelling process itself, which could involve putting statistical hypotheses to the test. It include deciding on a modelling strategy, coming up with test designs, building the model itself, and assessing the results. It heavily depends on the model used and the nature of the problem. This component does the primary analysis, which includes both numerical and graphical performance.\n",
        "\n",
        "1. **Which event takes more runtime?**\n",
        "\n",
        "Event name 'Total Render' is the event in which the overall time taken for ech events. This can be done with the below code by removing the total render data from the data file. Delta time of the start time and end time has been calculated and converted the delta time to seconds.\n",
        "\n",
        "```\n",
        "q7 =\"\"\"select q11.timestamp as start_dttm,q12.timestamp as end_dttm,q11.taskId taskId,q11.jobId jobId, q11.hostname, q11.eventName from (select * from cdata1 where  eventType='START') q11 inner join \n",
        "(select * from cdata1 where  eventType='STOP') q12 on q11.jobId=q12.jobId and q11.taskId=q12.taskId and q11.eventName=q12.eventName ;\"\"\"\n",
        "\n",
        "q_1_4=pysqldf(q7)\n",
        "\n",
        "q4 =\"\"\"select q_1_4.*, data2.x, data2.y, data2.level from q_1_4 inner join data2 on q_1_4.taskId = data2.taskId where q_1_4.eventName not like '%TotalRender%';\"\"\"\n",
        "data1_2=pysqldf(q4)\n",
        "\n",
        "data1_2[\"start_dttm\"]=data1_2[\"start_dttm\"].astype('datetime64')\n",
        "data1_2[\"end_dttm\"]=data1_2[\"end_dttm\"].astype('datetime64')\n",
        "data1_2['delta_dttm']=data1_2['end_dttm']-data1_2['start_dttm']\n",
        "```\n",
        "\n",
        "```\n",
        "data1_2['Avg_Time(in Seconds)'] = data1_2['delta_dttm'].dt.total_seconds()\n",
        "data1_2.groupby('eventName', as_index=False)['Avg_Time(in Seconds)'].mean()\n",
        "```\n",
        "\n",
        "The above code gives the average of each events as shown below.A graphical representation of the result is ploted using a bar chart and a form this it can be identified that Render takes more time for task run time with an average time of 41.208 seconds and Saving Config take very less time of 0.002 seconds. \n",
        " \n",
        "|eventName |  Avg_Time(in Seconds) |\n",
        "|-------|:-----|\n",
        "|Render |41.208220|\n",
        "|Saving Config|0.002476|\n",
        "|Tiling |0.973207|\n",
        "|Uploading|1.393641|\n",
        "|\n",
        "\n",
        "```\n",
        "ax = sns.barplot(x='eventName', y='Avg_Time(in Seconds)', data=data1_2,errwidth=0)\n",
        "```\n",
        "\n",
        "Plot1\n",
        "\n",
        "2. **which taskid/position takes more runtime?**\n",
        "\n",
        "The task which take more run time need to be identified for a better business perspective and could make a more change in developing a new system. From this data file it is identified that there are 65793 task id's and for analysis it is taken as top 10 task id's using the below code.\n",
        "\n",
        "```\n",
        "toptask=data1_2.groupby(['taskId','x','y'], as_index=False)['TotalTime(in Seconds)'].sum()\n",
        "toptask=toptask.sort_values(['TotalTime(in Seconds)'], ascending=False).head(10)\n",
        "toptask\n",
        "```\n",
        "\n",
        "|taskId|\tx\t|y|\tTotalTime(in Seconds)|\n",
        "|-------|:-----|:-----|:-----|\n",
        "|ef15022d-f816-4434-b41e-709cb996bc08|\t3\t|7\t|94.695|\n",
        "|76fb8e93-c3a6-456c-9661-3b7407800027\t|70\t|6\t|90.351|\n",
        "|33805\t83064f91-5a19-4526-8673-38ab28dd3ab7\t|14\t|1\t|89.292|\n",
        "|43629\ta95d501e-d5d5-4fb4-9119-98120bf6f4d5\t|91\t|105\t|83.498|\n",
        "|9602\t25b410b5-f5ef-4a2f-8b21-29175bca35fc\t|92\t|106|\t82.388|\n",
        "|53962\td194b27d-d421-47d3-ae41-eed07a00e8d4\t|92\t|107|\t79.752|\n",
        "|62904\tf4a61a45-2e92-4aa0-9219-4425ce0ec17e\t|93\t|107|\t77.479|\n",
        "|38388\t94bfb9b3-80c2-44e7-8869-c29a0007bbe0\t|93\t|108|\t75.919|\n",
        "|53582\td01f0571-c929-4bb8-9692-5ef053c1da1d\t|92\t|104|\t75.763|\n",
        "|20813\t51271d84-a39c-4a33-93c0-eda4648ad5bf\t|95\t|106|\t75.555|\n",
        "|\n",
        "|\n",
        "\n",
        "```\n",
        "toptask.plot.scatter(x='x',y='y', c='TotalTime',s=0.5, cmap='Greens')\n",
        "```\n",
        "\n",
        "Plot 2\n",
        "\n",
        "Graphical representation of the all the position taken in a scatter plot and it is identified that, area with dark indication  taked more runtime. \n",
        "\n",
        "3. **Which hostnames consume more power?**\n",
        "\n",
        "The power consumption of a host is determined by factors such as the type and number of components and their usage patterns. To determine which host are consuming more power, this can be measured using the power usage of each individual device. Here average power of each host name is taken using the below code.\n",
        "```\n",
        "avghostpower=cdata3.groupby('hostname', as_index=False)['powerDrawWatt'].mean()\n",
        "avghostpower=avghostpower.sort_values(['powerDrawWatt'], ascending=False).head(10)\n",
        "avghostpower\n",
        "```\n",
        "|hostname\t|powerDrawWatt|\n",
        "|-------|:-----|\n",
        "|a77ef58b13ad4c01b769dac8409af3f800000D| 106.247462|\n",
        "|db871cd77a544e13bc791a64a0c8ed5000000U|\t101.974324|\n",
        "|04dc4e9647154250beeee51b866b0715000011|\t101.549633|\n",
        "|5903af3699134795af7eafc605ae5fc700000H|\t99.057575|\n",
        "|8b6a0eebc87b4cb2b0539e81075191b9000016|\t98.698678|\n",
        "|04dc4e9647154250beeee51b866b0715000018|\t98.250353|\n",
        "|4ad946d4435c42dabb5073531ea4f31500000X|\t98.150566|\n",
        "|83ea61ac1ef54f27a3bf7bd0f41ecaa700000D|\t97.795836|\n",
        "|4c72fae95b9147189a0559269a6953ff000012|\t97.771817|\n",
        "|0745914f4de046078517041d70b22fe7000007|\t97.535805|\n",
        "|\n",
        "|\n",
        "\n",
        "```\n",
        "plt.bar(avghostpower.hostname, avghostpower.powerDrawWatt, color='b')\n",
        "addlabels(avghostpower.hostname, avghostpower.powerDrawWatt)\n",
        "plt.plot()\n",
        "plt.xticks(rotation=30, ha='right')\n",
        "plt.xlabel(\"Host Name\")\n",
        "plt.ylabel(\"Average Power Draw (in watts)\")\n",
        "plt.title(\"\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "Plot3\n",
        "\n",
        "From this plot it can be identified  the top 10 hostnames that consume more power and in that host **a77ef58b13ad4c01b769dac8409af3f800000D** consume power draw of **106.24W**\n",
        "\n",
        "\n",
        "4.  **What is average GPU temperature of each gpu card?**\n",
        "\n",
        "The average GPU temperature for a specific graphics card can vary depending on factors such as the specific model, its clock speed, and the workload it is handling.\n",
        "\n",
        "```\n",
        "avgtemp=cdata3.groupby('gpuSerial', as_index=False)['gpuTempC'].mean()\n",
        "avgtemp=avgtemp.sort_values(['gpuTempC'], ascending=False).head(10)\n",
        "avgtemp\n",
        "```\n",
        "|gpuSerial\t|gpuTempC|\n",
        "|-------|:-----|\n",
        "|\t323617043033\t|48.926716|\n",
        "|\t323617021463\t|48.153231|\n",
        "|\t325217084671\t|48.128925|\n",
        "|\t323217055992\t|48.008672|\n",
        "|\t323217056368\t|47.523046|\n",
        "|\t323617020525\t|47.379081|\n",
        "|\t323617042479\t|47.255163|\n",
        "|\t325017017810\t|47.247498|\n",
        "|\t323617042764\t|47.109333|\n",
        "|\t323617042596\t|47.088608|\n",
        "|\n",
        "|\n",
        "\n",
        "```\n",
        "x = avgtemp.gpuSerial\n",
        "y = avgtemp.gpuTempC\n",
        "# setting figure size by using figure() function \n",
        "plt.figure(figsize = (10, 7))\n",
        "\n",
        "plt.bar(x, y)\n",
        "# calling the function to add value labels\n",
        "addlabels(x, y)\n",
        "\n",
        "plt.xticks(rotation=30, ha='right')\n",
        "plt.xlabel(\"GPU Serial Number\")\n",
        "plt.ylabel(\"GPU Temperature\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "Plot4\n",
        "\n",
        "The gpu card serial number **323617043033** take more temperature of an average of **48.93°C**.\n",
        "\n",
        "\n",
        "5.  **What is the relationship between gpu utilisation percentage gpu memory utilisation percentage?**\n",
        "\n",
        "The GPU utilization percentage refers to the amount of time that the GPU's processing units are actively being used, while the GPU memory utilization percentage refers to the amount of the GPU's memory that is currently being used. \n",
        "\n",
        "```\n",
        "rel=cdata3.groupby('gpuSerial', as_index=False)['gpuUtilPerc','gpuMemUtilPerc'].mean()\n",
        "rel=rel.sort_values(['gpuUtilPerc'], ascending=False)\n",
        "rel.index\n",
        "```\n",
        "```\n",
        "plt.scatter(x=rel.gpuUtilPerc, y=rel.gpuMemUtilPerc, c = 'lightgreen', edgecolor = 'darkgreen');\n",
        "plt.xlabel(\"GPU Memory Utilisation Percentage\")\n",
        "plt.ylabel(\"GPU Utilisation Percentage\")\n",
        "z = np.polyfit(rel.gpuUtilPerc, rel.gpuMemUtilPerc, 1)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(rel.gpuUtilPerc,p(rel.gpuUtilPerc),\"r--\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "Plot5\n",
        "\n",
        "From the above plot it can be can be identified that when a gpu core utilisation increases, gpu memory utilisation also get increased. The two percentages are related, as a higher GPU utilization percentage typically corresponds to a higher GPU memory utilization percentage, as the GPU is using more resources to process data.\n",
        "\n",
        "6.  **What is the average percentage of power draw consumption for each event name?**\n",
        "\n",
        "```\n",
        "q1_3 =\"\"\"select * from data1_2 inner join cdata3 on data1_2.hostname = cdata3.hostname and data1_2.start_dttm <= cdata3.timestamp and data1_2.end_dttm >= cdata3.timestamp;\"\"\"\n",
        "data1_3=pysqldf(q1_3)\n",
        "\n",
        "eventpowerDraw=data1_3.groupby('eventName', as_index=False)['powerDrawWatt'].mean()\n",
        "eventpowerDraw\n",
        "```\n",
        "\n",
        "|eventName\t|powerDrawWatt|\n",
        "|-------|:-----|\n",
        "| Render|\t97.045833|\n",
        "|\tSaving Config|\t36.087685|\n",
        "|\tTiling|\t44.756076|\n",
        "|\tUploading|\t40.495508|\n",
        "|\n",
        "|\n",
        "\n",
        "```\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.pie(eventpowerDraw.powerDrawWatt, labels=eventpowerDraw.eventName, autopct='%.1f%%',\n",
        "       wedgeprops={'linewidth': 3.0, 'edgecolor': 'w'},\n",
        "       textprops={'size': 'x-large'})\n",
        "ax.set_title('Power consumption of each events', fontsize=18)\n",
        "plt.tight_layout()\n",
        "```\n",
        "\n",
        "Plot6\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SH__kxCG-lTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "asdasdsad\n"
      ],
      "metadata": {
        "id": "I4ehvDSPi8h3"
      }
    }
  ]
}